{"cells":[{"cell_type":"markdown","source":["# Project: Machine Learning with Spark\n# By: Phuong NGUYEN & Majda EL MOUSSAOUI"],"metadata":{}},{"cell_type":"markdown","source":["#### Introduction\n\nThe objective of this mini-project is to use different Spark machine learning libraries to build a predictive model.\n\nThe provided dataset comes from [UCI Machine Learning repository](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset). It contains the hourly and daily count of rental bikes between years 2011 and 2012 in Capital bikeshare system with the corresponding weather and seasonal information.\n\nThe task of this project is to predict hourly bike demand based on the provided features. Since the target variable is known, supervised learning is thus used.\n\nAs the target is continuous, we will build several regression models, tune them and compare the results.\n\nWe will proceed the project with the following steps:\n\n1. Load and preprocess the data\n2. Build a first linear regression model\n3. Tune linear regression model\n4. Result analysis\n5. Feature engineering\n6. Try other regression models"],"metadata":{}},{"cell_type":"markdown","source":["#### 1. Load and preprocess the data"],"metadata":{}},{"cell_type":"markdown","source":["The dataset is provided under csv format. The following code loads it by keeping the header and the original schema."],"metadata":{}},{"cell_type":"code","source":["data = spark.read.csv('/FileStore/tables/ml/Bike_Rental_UCI_dataset.csv', header=True, inferSchema=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["Let's have a look at 5 first rows of the dataset."],"metadata":{}},{"cell_type":"code","source":["data.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+\nseason| yr|mnth| hr|holiday|workingday|weathersit|temp| hum|windspeed|dayOfWeek|days|demand|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+\n     1|  0|   1|  0|      0|         0|         1|0.24|0.81|      0.0|      Sat|   0|    16|\n     1|  0|   1|  1|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    40|\n     1|  0|   1|  2|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    32|\n     1|  0|   1|  3|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|    13|\n     1|  0|   1|  4|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|     1|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["According to [UCI Machine Learning repository](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset), here is a short description of each feature in the dataset:\n\n- season : season (1: winter, 2: spring, 3: summer, 4: fall)\n- yr : year (0: 2011, 1: 2012)\n- mnth : month (1 to 12)\n- hr : hour (0 to 23)\n- holiday : whether day is holiday or not (extracted from [Web Link](https://dchr.dc.gov/page/holiday-schedules))\n- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n- weathersit :\n  - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n  - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n  - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n  - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\n- hum: Normalized humidity. The values are divided to 100 (max)\n- windspeed: Normalized wind speed. The values are divided to 67 (max)\n- dayOfWeek: day of the week\n- demand: count of total rental bikes (TARGET VARIABLE)"],"metadata":{}},{"cell_type":"code","source":["# print out the dataframe schema, to ensure that all variables are in correct data type\ndata.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- season: integer (nullable = true)\n-- yr: integer (nullable = true)\n-- mnth: integer (nullable = true)\n-- hr: integer (nullable = true)\n-- holiday: integer (nullable = true)\n-- workingday: integer (nullable = true)\n-- weathersit: integer (nullable = true)\n-- temp: double (nullable = true)\n-- hum: double (nullable = true)\n-- windspeed: double (nullable = true)\n-- dayOfWeek: string (nullable = true)\n-- days: integer (nullable = true)\n-- demand: integer (nullable = true)\n\n</div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["Almost all columns are of numerical values, except dayOfWeek. In order to get the data prepared for machine learning task, we need to encode days of week with numerical values. \nLet's check the different values in dayOfWeek column."],"metadata":{}},{"cell_type":"code","source":["data.select(\"dayOfWeek\").distinct().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+\ndayOfWeek|\n+---------+\n      Sun|\n      Mon|\n      Sat|\n      Wed|\n      Tue|\n      Fri|\n      Thr|\n+---------+\n\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["Hereunder, we create a mapping dictionary to map each value in dayOfWeek column to a numerical value. Monday is encoded as 0, Tuesday is encoded as 1 and so on."],"metadata":{}},{"cell_type":"code","source":["from itertools import chain\nfrom pyspark.sql.functions import create_map, lit\n\n# create a dictionary that maps each day of week to a numerical value\nmapping = {'Mon': 0,\n           'Tue': 1,\n           'Wed': 2,\n           'Thr': 3,\n           'Fri': 4,\n           'Sat': 5,\n           'Sun': 6}\n\n# create a new column named day_cat\nmapping_expr = create_map([lit(x) for x in chain(*mapping.items())])\n\ndata = data.withColumn('day_cat', mapping_expr[data['dayOfWeek']])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["Let's have a look at the data after encoding dayOfWeek."],"metadata":{}},{"cell_type":"code","source":["data.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+\nseason| yr|mnth| hr|holiday|workingday|weathersit|temp| hum|windspeed|dayOfWeek|days|demand|day_cat|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+\n     1|  0|   1|  0|      0|         0|         1|0.24|0.81|      0.0|      Sat|   0|    16|      5|\n     1|  0|   1|  1|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    40|      5|\n     1|  0|   1|  2|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    32|      5|\n     1|  0|   1|  3|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|    13|      5|\n     1|  0|   1|  4|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|     1|      5|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["In order to train machine learning models, we need a transformer that combines a list of columns into a single vector column. For this purpose, we use VectorAssembler, that takes all the features (except dayOfWeek) as input and outputs a new column named \"features\"."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler, VectorIndexer"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["# create a feature vector\nvectorAssembler = VectorAssembler(\n  inputCols= [\n    'season',\n    'yr',\n    'mnth',\n    'hr',\n    'holiday',\n    'workingday',\n    'weathersit',\n    'temp',\n    'hum',\n    'windspeed',\n    'days',\n    'day_cat'\n    ],\n   outputCol = 'features'\n )\n\noutput = vectorAssembler.transform(data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["Have a look at the features and target after applying VectorAssembler."],"metadata":{}},{"cell_type":"code","source":["output.select(\"features\", \"demand\").show(10, truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------------------------------+------+\nfeatures                                              |demand|\n+------------------------------------------------------+------+\n(12,[0,2,6,7,8,11],[1.0,1.0,1.0,0.24,0.81,5.0])       |16    |\n[1.0,0.0,1.0,1.0,0.0,0.0,1.0,0.22,0.8,0.0,0.0,5.0]    |40    |\n[1.0,0.0,1.0,2.0,0.0,0.0,1.0,0.22,0.8,0.0,0.0,5.0]    |32    |\n[1.0,0.0,1.0,3.0,0.0,0.0,1.0,0.24,0.75,0.0,0.0,5.0]   |13    |\n[1.0,0.0,1.0,4.0,0.0,0.0,1.0,0.24,0.75,0.0,0.0,5.0]   |1     |\n[1.0,0.0,1.0,5.0,0.0,0.0,2.0,0.24,0.75,0.0896,0.0,5.0]|1     |\n[1.0,0.0,1.0,6.0,0.0,0.0,1.0,0.22,0.8,0.0,0.0,5.0]    |2     |\n[1.0,0.0,1.0,7.0,0.0,0.0,1.0,0.2,0.86,0.0,0.0,5.0]    |3     |\n[1.0,0.0,1.0,8.0,0.0,0.0,1.0,0.24,0.75,0.0,0.0,5.0]   |8     |\n[1.0,0.0,1.0,9.0,0.0,0.0,1.0,0.32,0.76,0.0,0.0,5.0]   |14    |\n+------------------------------------------------------+------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["We split data into train and test set."],"metadata":{}},{"cell_type":"code","source":["train, test = output.randomSplit([0.8, 0.2])\nprint (\"We have %d training examples and %d test examples.\" % (train.count(), test.count()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">We have 13887 training examples and 3492 test examples.\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["train.cache()\ntest.cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[48]: DataFrame[season: int, yr: int, mnth: int, hr: int, holiday: int, workingday: int, weathersit: int, temp: double, hum: double, windspeed: double, dayOfWeek: string, days: int, demand: int, day_cat: int, features: vector]</div>"]}}],"execution_count":23},{"cell_type":"markdown","source":["#### 2. Build a first linear regression model"],"metadata":{}},{"cell_type":"markdown","source":["In this section, we build a first linear regression model with some pre-defined hyperparameters. After fitting the model into training set, we will display the evaluation metrics (Mean Absolute Error and R2) on training set and on test set."],"metadata":{}},{"cell_type":"code","source":["# import Linear Regression module\nfrom pyspark.ml.regression import LinearRegression"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":26},{"cell_type":"code","source":["# initialize Linear Regression model with some hyperparameters\nlr = LinearRegression(maxIter=100, elasticNetParam=0.3, featuresCol=\"features\", labelCol=\"demand\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"code","source":["# fit to training set\nlrm = lr.fit(train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":28},{"cell_type":"code","source":["# print out MAE and R2 on train data\ntrainingSummary = lrm.summary\nprint(\"Mean Absolute Error (MAE) on train data = %f\" % trainingSummary.meanAbsoluteError)\nprint(\"R Squared (R2) on train data = %f\" % trainingSummary.r2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Mean Absolute Error (MAE) on train data = 105.700559\nR Squared (R2) on train data = 0.387069\n</div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["MAE measures the absolute differences between predicted values by the model and the actual values. However, MAE alone is meaningless until we compare with the actual “demand” value, such as mean and standard deviation."],"metadata":{}},{"cell_type":"code","source":["train.select(\"demand\").describe().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+------------------+\nsummary|            demand|\n+-------+------------------+\n  count|             13887|\n   mean|188.93130265716138|\n stddev|180.29719701038317|\n    min|                 1|\n    max|               977|\n+-------+------------------+\n\n</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["It can be seen that the demand in training set has a mean of 188.9 and a standard deviation of 180.3. While our Mean Absolute Error is 105.7 which is lower than standard deviation. This is a not bad result.\n\nHowever, R2 square is 0.387. This metric indicates that in our model, approximate 38.7% of the variability in “demand” can be explained using the model. This is an average result and there is still room for improvement.\n\nNext, we will make predictions on the test data and print out MAE and R2."],"metadata":{}},{"cell_type":"code","source":["# make predictions on test data\nlr_preds = lrm.transform(test)\n\nlr_preds.select(\"prediction\", \"demand\", \"features\").show(5)\n\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nlr_evaluator = RegressionEvaluator(predictionCol=\"prediction\",\\\n                                   labelCol=\"demand\")\n\n# print out MAE and R2 on test data\nprint(\"Mean Absolute Error (MAE) on test data = %g\" % lr_evaluator.evaluate(lr_preds, {lr_evaluator.metricName: \"mae\"}))\nprint(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_preds, {lr_evaluator.metricName: \"r2\"}))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------+------+--------------------+\n         prediction|demand|            features|\n+-------------------+------+--------------------+\n -64.37809792230935|    13|[1.0,0.0,1.0,0.0,...|\n-103.38032779581489|    33|[1.0,0.0,1.0,0.0,...|\n -49.98451668775128|    28|[1.0,0.0,1.0,0.0,...|\n-28.834586057464353|    17|[1.0,0.0,1.0,0.0,...|\n -45.31205265098258|    14|[1.0,0.0,1.0,0.0,...|\n+-------------------+------+--------------------+\nonly showing top 5 rows\n\nMean Absolute Error (MAE) on test data = 108\nR Squared (R2) on test data = 0.388325\n</div>"]}}],"execution_count":33},{"cell_type":"markdown","source":["While R2 is approximately same as on training set, MAE is a bit worse. \n\nIn next section, we will tune this Linear Regression model by doing cross validation."],"metadata":{}},{"cell_type":"markdown","source":["#### 3. Tune linear regression model"],"metadata":{}},{"cell_type":"markdown","source":["In this section, we tune the linear regression using cross-validation. We will build a pipeline and search for best parameters in a parameter grid."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":37},{"cell_type":"markdown","source":["We print out the parameters explanation in order to build parameter grid."],"metadata":{}},{"cell_type":"code","source":["lr.explainParams()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[25]: &#39;aggregationDepth: suggested depth for treeAggregate (&gt;= 2). (default: 2)\\nelasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0, current: 0.3)\\nepsilon: The shape parameter to control the amount of robustness. Must be &gt; 1.0. Only valid when loss is huber (default: 1.35)\\nfeaturesCol: features column name. (default: features, current: features)\\nfitIntercept: whether to fit an intercept term. (default: True)\\nlabelCol: label column name. (default: label, current: demand)\\nloss: The loss function to be optimized. Supported options: squaredError, huber. (default: squaredError)\\nmaxIter: max number of iterations (&gt;= 0). (default: 100, current: 100)\\npredictionCol: prediction column name. (default: prediction)\\nregParam: regularization parameter (&gt;= 0). (default: 0.0)\\nsolver: The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (default: auto)\\nstandardization: whether to standardize the training features before fitting the model. (default: True)\\ntol: the convergence tolerance for iterative algorithms (&gt;= 0). (default: 1e-06)\\nweightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)&#39;</div>"]}}],"execution_count":39},{"cell_type":"markdown","source":["We choose to tune:\n- number of iterations\n- regularization parameter\n- elastic net parameter\n- solver algorithm for optimization"],"metadata":{}},{"cell_type":"code","source":["pipeLine = Pipeline()\npipeLine.setStages([lr])\n\ngridBuilder = ParamGridBuilder().addGrid(lr.maxIter, [10, 50, 100, 150, 200])\\\n                                .addGrid(lr.regParam, [0, 10, 100, 1000])\\\n                                .addGrid(lr.elasticNetParam, [0, 0.1, 0.3, 0.7, 1.0])\\\n                                .addGrid(lr.solver, [\"auto\", \"normal\", \"l-bfgs\"])\\\n                                .build()\n\ncv = CrossValidator(estimator = lr,\n                    estimatorParamMaps = gridBuilder,\n                    evaluator = lr_evaluator)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":41},{"cell_type":"code","source":["cvm = cv.fit(train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n</div>"]}}],"execution_count":42},{"cell_type":"markdown","source":["After fitting the cross validation on training set, we print out the best model parameters."],"metadata":{}},{"cell_type":"code","source":["best_lr_model = cvm.bestModel\nbest_lr_model.explainParams()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[41]: &#39;aggregationDepth: suggested depth for treeAggregate (&gt;= 2) (default: 2)\\nelasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty (default: 0.0, current: 0.0)\\nepsilon: The shape parameter to control the amount of robustness. Must be &gt; 1.0. (default: 1.35)\\nfeaturesCol: features column name (default: features, current: features)\\nfitIntercept: whether to fit an intercept term (default: True)\\nlabelCol: label column name (default: label, current: demand)\\nloss: The loss function to be optimized. Supported options: squaredError, huber. (Default squaredError) (default: squaredError)\\nmaxIter: maximum number of iterations (&gt;= 0) (default: 100, current: 10)\\npredictionCol: prediction column name (default: prediction)\\nregParam: regularization parameter (&gt;= 0) (default: 0.0, current: 0.0)\\nsolver: The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (Default auto) (default: auto, current: l-bfgs)\\nstandardization: whether to standardize the training features before fitting the model (default: True)\\ntol: the convergence tolerance for iterative algorithms (&gt;= 0) (default: 1e-06)\\nweightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0 (undefined)&#39;</div>"]}}],"execution_count":44},{"cell_type":"markdown","source":["The best model has the following parameters:\n- number of iterations: 10\n- regularization parameter: 0.0\n- elastic net parameter: 0.0\n- solver algorithm for optimization: l-bfgs\n\nNext, we print out MAE and R2 score on training and test set."],"metadata":{}},{"cell_type":"code","source":["# print out MAE and R2 on train data\nbest_lr_summary = best_lr_model.summary\n\nprint(\"Mean Absolute Error (MAE) on train data = %f\" % best_lr_summary.meanAbsoluteError)\nprint(\"R Squared (R2) on train data = %f\" % best_lr_summary.r2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Mean Absolute Error (MAE) on train data = 105.706959\nR Squared (R2) on train data = 0.386902\n</div>"]}}],"execution_count":46},{"cell_type":"code","source":["# make predictions on test data\nbest_lr_preds = best_lr_model.transform(test)\n\nbest_lr_preds.select(\"prediction\", \"demand\", \"features\").show(5)\n\n# print out MAE and R2 on test data\nprint(\"Mean Absolute Error (MAE) on test data = %g\" % lr_evaluator.evaluate(best_lr_preds, {lr_evaluator.metricName: \"mae\"}))\nprint(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(best_lr_preds, {lr_evaluator.metricName: \"r2\"}))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------+------+--------------------+\n         prediction|demand|            features|\n+-------------------+------+--------------------+\n -61.84341939075479|    13|[1.0,0.0,1.0,0.0,...|\n -99.09667658180496|    33|[1.0,0.0,1.0,0.0,...|\n-49.020422755784814|    28|[1.0,0.0,1.0,0.0,...|\n -31.29103690483463|    17|[1.0,0.0,1.0,0.0,...|\n -44.72576863431983|    14|[1.0,0.0,1.0,0.0,...|\n+-------------------+------+--------------------+\nonly showing top 5 rows\n\nMean Absolute Error (MAE) on test data = 107.982\nR Squared (R2) on test data = 0.388478\n</div>"]}}],"execution_count":47},{"cell_type":"markdown","source":["It can be seen that MAE and R2 score on test set are slighly compared to the model built in previous section."],"metadata":{}},{"cell_type":"markdown","source":["#### 4. Result analysis"],"metadata":{}},{"cell_type":"markdown","source":["In this section, we will compare true demand with model prediction to understand where the model performs well and where it performs badly.\n\nWe will be using best_lr_preds dataframe from previous section, which contains prediction made by best Linear Regression model after cross validation.\n\nLet's display 5 first rows of best_lr_preds to see how it looks like."],"metadata":{}},{"cell_type":"code","source":["best_lr_preds.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+---+----+---+-------+----------+----------+----+----+-------------------+---------+----+------+-------+--------------------+-------------------+\nseason| yr|mnth| hr|holiday|workingday|weathersit|temp| hum|          windspeed|dayOfWeek|days|demand|day_cat|            features|         prediction|\n+------+---+----+---+-------+----------+----------+----+----+-------------------+---------+----+------+-------+--------------------+-------------------+\n     1|  0|   1|  0|      0|         0|         1|0.04|0.45|             0.2537|      Sat|  19|    13|      5|[1.0,0.0,1.0,0.0,...| -61.84341939075479|\n     1|  0|   1|  0|      0|         0|         1|0.16| 0.8|             0.1045|      Sun|  26|    33|      6|[1.0,0.0,1.0,0.0,...| -99.09667658180496|\n     1|  0|   1|  0|      0|         0|         1|0.18|0.55|                0.0|      Sat|  13|    28|      5|[1.0,0.0,1.0,0.0,...|-49.020422755784814|\n     1|  0|   1|  0|      0|         0|         2|0.46|0.88|             0.2985|      Sun|   1|    17|      6|[1.0,0.0,1.0,0.0,...| -31.29103690483463|\n     1|  0|   1|  0|      0|         1|         1|0.12| 0.5|0.19399999999999998|      Fri|  12|    14|      4|[1.0,0.0,1.0,0.0,...| -44.72576863431983|\n+------+---+----+---+-------+----------+----------+----+----+-------------------+---------+----+------+-------+--------------------+-------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":51},{"cell_type":"markdown","source":["In order to understand where the linear regression model performs well or badly, we will group by the average and standard deviation of real demand and prediction by hour, season and month. To visualize the gap easily, we will prioritize charts over tables."],"metadata":{}},{"cell_type":"code","source":["import pyspark.sql.functions as F"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":53},{"cell_type":"markdown","source":["Average and standard deviation of real demand and prediction by **hour**:"],"metadata":{}},{"cell_type":"code","source":["# average demand and average prediction by hour\nbest_lr_preds.groupBy('hr')\\\n             .agg(F.avg('demand'), F.avg('prediction'))\\\n             .orderBy('hr', ascending=True)\\\n             .toPandas()\\\n             .plot.line(x=\"hr\", y=[\"avg(demand)\", \"avg(prediction)\"])"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["# standard deviation of demand and prediction by hour\nbest_lr_preds.groupBy('hr')\\\n             .agg(F.stddev('demand'), F.stddev('prediction'))\\\n             .orderBy('hr', ascending=True)\\\n             .toPandas()\\\n             .plot.line(x=\"hr\", y=[\"stddev_samp(demand)\", \"stddev_samp(prediction)\"])"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":["Linear regression model is not able to capture the demand pattern: average and standard deviation of prediction are pretty far from those of real demand. Especially on rush hours, when both average and standard deviation of real demand are at the peak, the model fails to make a decent prediction."],"metadata":{}},{"cell_type":"markdown","source":["Average and standard deviation of real demand and prediction by **season**:"],"metadata":{}},{"cell_type":"code","source":["# average demand and average prediction by season\nbest_lr_preds.groupBy('season')\\\n             .agg(F.avg('demand'), F.avg('prediction'))\\\n             .orderBy('season', ascending=True)\\\n             .toPandas()\\\n             .plot.bar(x=\"season\", y=[\"avg(demand)\", \"avg(prediction)\"])"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["# standard deviation of demand and prediction by season\nbest_lr_preds.groupBy('season')\\\n             .agg(F.stddev('demand'), F.stddev('prediction'))\\\n             .orderBy('season', ascending=True)\\\n             .toPandas()\\\n             .plot.bar(x=\"season\", y=[\"stddev_samp(demand)\", \"stddev_samp(prediction)\"])"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":["The model's average prediction per season is pretty near the average target value. This is also true with standard deviation in Spring (season 1).\nHowever, for remaining seasons, there is still room for improvement since standard deviation of real demand and that of prediction are far from each other."],"metadata":{}},{"cell_type":"markdown","source":["Average and standard deviation of real demand and prediction by **month**:"],"metadata":{}},{"cell_type":"code","source":["# average demand and average prediction by month\nbest_lr_preds.groupBy('mnth')\\\n             .agg(F.avg('demand'), F.avg('prediction'))\\\n             .orderBy('mnth', ascending=True)\\\n             .toPandas()\\\n             .plot.line(x=\"mnth\", y=[\"avg(demand)\", \"avg(prediction)\"])"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"code","source":["# standard deviation of demand and prediction by month\nbest_lr_preds.groupBy('mnth')\\\n             .agg(F.stddev('demand'), F.stddev('prediction'))\\\n             .orderBy('mnth', ascending=True)\\\n             .toPandas()\\\n             .plot.line(x=\"mnth\", y=[\"stddev_samp(demand)\", \"stddev_samp(prediction)\"])"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"markdown","source":["Same as season, the model captures pretty well monthly trend in average demand. In contrast, the model doesn't seem to understand the trend in standard deviation."],"metadata":{}},{"cell_type":"markdown","source":["#### 5. Feature engineering"],"metadata":{}},{"cell_type":"markdown","source":["In previous sections, we built, trained and tuned linear regression model on the provided dataset, without taking care of categorical features.\nIndeed, we treated categorical features in same manner as numerical features. For example, season can have value 1, 2, 3 and 4 but this represent four different seasons thus should be taken as categorical features.\n\nIn this section, we will create dummy variables from categorical features in order to improve the accuracy of the model. These categorical features include: season, mnth, hr, weathersit and day_cat. Yr, holiday and workingday take either 0 or 1 as value, thus are not included in the categorical features from which we'll create dummy variables."],"metadata":{}},{"cell_type":"code","source":["# have a look at the data\ndata.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+\nseason| yr|mnth| hr|holiday|workingday|weathersit|temp| hum|windspeed|dayOfWeek|days|demand|day_cat|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+\n     1|  0|   1|  0|      0|         0|         1|0.24|0.81|      0.0|      Sat|   0|    16|      5|\n     1|  0|   1|  1|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    40|      5|\n     1|  0|   1|  2|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    32|      5|\n     1|  0|   1|  3|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|    13|      5|\n     1|  0|   1|  4|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|     1|      5|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":68},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer, OneHotEncoder\nfrom pyspark.sql.functions import col\n\ncat_cols = ['season', 'mnth', 'hr', 'weathersit', 'day_cat']\n\nindexers = [\n    StringIndexer(inputCol=col, outputCol=\"{0}_indexed\".format(col))\n    for col in cat_cols\n]\n\nencoders = [\n    OneHotEncoder(\n        inputCol=indexer.getOutputCol(),\n        outputCol=\"{0}_encoded\".format(indexer.getOutputCol())) \n    for indexer in indexers\n]\n\nassembler = VectorAssembler(\n    inputCols=[encoder.getOutputCol() for encoder in encoders],\n    outputCol=\"features\"\n)\n\n\npipeline = Pipeline(stages=indexers + encoders + [assembler])\ndata_transformed = pipeline.fit(data).transform(data)\ndata_transformed.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+--------------+------------+----------+------------------+---------------+----------------------+--------------------+------------------+--------------------------+-----------------------+--------------------+\nseason| yr|mnth| hr|holiday|workingday|weathersit|temp| hum|windspeed|dayOfWeek|days|demand|day_cat|season_indexed|mnth_indexed|hr_indexed|weathersit_indexed|day_cat_indexed|season_indexed_encoded|mnth_indexed_encoded|hr_indexed_encoded|weathersit_indexed_encoded|day_cat_indexed_encoded|            features|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+--------------+------------+----------+------------------+---------------+----------------------+--------------------+------------------+--------------------------+-----------------------+--------------------+\n     1|  0|   1|  0|      0|         0|         1|0.24|0.81|      0.0|      Sat|   0|    16|      5|           2.0|        10.0|      17.0|               0.0|            0.0|         (3,[2],[1.0])|     (11,[10],[1.0])|   (23,[17],[1.0])|             (3,[0],[1.0])|          (6,[0],[1.0])|(46,[2,13,31,37,4...|\n     1|  0|   1|  1|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    40|      5|           2.0|        10.0|      19.0|               0.0|            0.0|         (3,[2],[1.0])|     (11,[10],[1.0])|   (23,[19],[1.0])|             (3,[0],[1.0])|          (6,[0],[1.0])|(46,[2,13,33,37,4...|\n     1|  0|   1|  2|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    32|      5|           2.0|        10.0|      21.0|               0.0|            0.0|         (3,[2],[1.0])|     (11,[10],[1.0])|   (23,[21],[1.0])|             (3,[0],[1.0])|          (6,[0],[1.0])|(46,[2,13,35,37,4...|\n     1|  0|   1|  3|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|    13|      5|           2.0|        10.0|      23.0|               0.0|            0.0|         (3,[2],[1.0])|     (11,[10],[1.0])|        (23,[],[])|             (3,[0],[1.0])|          (6,[0],[1.0])|(46,[2,13,37,40],...|\n     1|  0|   1|  4|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|     1|      5|           2.0|        10.0|      22.0|               0.0|            0.0|         (3,[2],[1.0])|     (11,[10],[1.0])|   (23,[22],[1.0])|             (3,[0],[1.0])|          (6,[0],[1.0])|(46,[2,13,36,37,4...|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+--------------+------------+----------+------------------+---------------+----------------------+--------------------+------------------+--------------------------+-----------------------+--------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":69},{"cell_type":"code","source":["train, test = data_transformed.randomSplit([0.8, 0.2])\nprint (\"We have %d training examples and %d test examples.\" % (train.count(), test.count()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">We have 13878 training examples and 3501 test examples.\n</div>"]}}],"execution_count":70},{"cell_type":"code","source":["train.cache()\ntest.cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[34]: DataFrame[season: int, yr: int, mnth: int, hr: int, holiday: int, workingday: int, weathersit: int, temp: double, hum: double, windspeed: double, dayOfWeek: string, days: int, demand: int, day_cat: int, season_indexed: double, mnth_indexed: double, hr_indexed: double, weathersit_indexed: double, day_cat_indexed: double, season_indexed_encoded: vector, mnth_indexed_encoded: vector, hr_indexed_encoded: vector, weathersit_indexed_encoded: vector, day_cat_indexed_encoded: vector, features: vector]</div>"]}}],"execution_count":71},{"cell_type":"code","source":["# initialize Linear Regression model with some hyperparameters\nlr = LinearRegression(maxIter=100, elasticNetParam=0.3, featuresCol=\"features\", labelCol=\"demand\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":72},{"cell_type":"code","source":["# fit to training set\nlrm = lr.fit(train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":73},{"cell_type":"code","source":["# print out MAE and R2 on train data\ntrainingSummary = lrm.summary\nprint(\"Mean Absolute Error (MAE) on train data = %f\" % trainingSummary.meanAbsoluteError)\nprint(\"R Squared (R2) on train data = %f\" % trainingSummary.r2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Mean Absolute Error (MAE) on train data = 82.396250\nR Squared (R2) on train data = 0.609066\n</div>"]}}],"execution_count":74},{"cell_type":"code","source":["# make predictions on test data\nlr_preds = lrm.transform(test)\n\nlr_preds.select(\"prediction\", \"demand\", \"features\").show(5)\n\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nlr_evaluator = RegressionEvaluator(predictionCol=\"prediction\",\\\n                                   labelCol=\"demand\")\n\n# print out MAE and R2 on test data\nprint(\"Mean Absolute Error (MAE) on test data = %g\" % lr_evaluator.evaluate(lr_preds, {lr_evaluator.metricName: \"mae\"}))\nprint(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_preds, {lr_evaluator.metricName: \"r2\"}))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------+------+--------------------+\n         prediction|demand|            features|\n+-------------------+------+--------------------+\n -30.15189316152857|    16|(46,[2,13,31,37,4...|\n -36.84676778336571|     7|(46,[2,13,31,37,4...|\n-24.045911206230315|    14|(46,[2,13,31,37,4...|\n-25.996506974357132|    11|(46,[2,13,31,37,4...|\n-25.996506974357132|    13|(46,[2,13,31,37,4...|\n+-------------------+------+--------------------+\nonly showing top 5 rows\n\nMean Absolute Error (MAE) on test data = 84.8634\nR Squared (R2) on test data = 0.596587\n</div>"]}}],"execution_count":75},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":76},{"cell_type":"markdown","source":["#### 6. Try other regression models"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":78}],"metadata":{"name":"bike_lab","notebookId":3546636032352226},"nbformat":4,"nbformat_minor":0}
